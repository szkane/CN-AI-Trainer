---
title: 11.数据集划分方法
time: 2024-06-18 10:20
tags: []
---

机器学习中的数据集划分方法是模型训练和评估过程中的重要部分，选择合适的划分方法可以影响模型的性能和泛化能力。以下是几种常见的数据集划分方法及其适用场景：

### 1. 随机划分法：训练集/验证集/测试集划分（Train/Validation/Test Split）

**描述**：将数据集随机划分为训练集、验证集和测试集，通常按 70%/15%/15%或 80%/10%/10%的比例划分。

**适用场景**：适用于大多数数据集，尤其是数据量较大且分布均匀的情况。

**优点**：

- 简单易行。
- 计算开销低。

**缺点**：

- 结果依赖于划分的随机性，可能导致不同划分下结果不一致。
- 对数据量较少的情况不太适用。

**实际例子**：
假设有一个包含 10,000 条样本的数据集，随机划分为 80%训练集（8,000 条）、10%验证集（1,000 条）和 10%测试集（1,000 条）。

### 2. 交叉验证（Cross-Validation）

**描述**：将数据集划分为 k 个子集，每次用 k-1 个子集训练模型，剩下的一个子集进行验证，重复 k 次，每次选择不同的子集作为验证集。最常用的是 k=5 或 k=10。

**适用场景**：适用于数据量较小或模型需要稳定评估的情况。

**优点**：

- 评估结果稳定，减少因划分随机性带来的影响。
- 充分利用所有数据。

**缺点**：

- 计算开销较大。
- 对于非常大的数据集，计算成本较高。

**实际例子**：
对于一个包含 1,000 条样本的数据集，进行 5 折交叉验证，每次使用 800 条样本训练，200 条样本验证，重复 5 次。

### 3. 留一法交叉验证（Leave-One-Out Cross-Validation, LOOCV）

**描述**：每次选择一个样本作为验证集，其余样本作为训练集，重复 n 次（n 为样本数量）。

**适用场景**：适用于小数据集和高要求的模型评估。

**优点**：

- 最大限度利用数据。
- 评估结果高度可靠。

**缺点**：

- 计算开销非常大。
- 对于非常大的数据集不实用。

**实际例子**：
对于一个包含 100 条样本的数据集，每次用 99 条样本训练，1 条样本验证，重复 100 次。

### 3.1 留 P 法交叉验证 (P-fold cross-validation)

**描述**：一种留一法的变种，每次将数据集中 P 条数据作为验证集，其余数据作为训练集。

**适用场景**：数据量适中，且希望平衡计算开销和数据利用率的场景。

**实际例子**：对于一个包含 100 条数据的数据集，每次用 20 条数据验证，其余 80 条数据训练，重复 5 次。

**优点**：

- 比 LOOCV 计算量小
- 较全面地评估模型性能

**缺点**：

- 计算量依然较大

### 4. 自助法（Bootstrap）

**描述**：从原始数据集中有放回地随机抽取样本生成新的训练集，未被抽取的样本作为验证集。通常重复多次进行评估。

**适用场景**：适用于不平衡数据集和评估模型的稳定性。

**优点**：

- 可以生成多个不同的训练集。
- 有助于评估模型的稳定性和泛化能力。

**缺点**：

- 可能导致某些样本被多次抽取，而另一些样本未被抽取。
- 计算开销较大。

**实际例子**：
对于一个包含 1,000 条样本的数据集，进行多次自助法抽样，每次抽取 1,000 条样本作为训练集，未被抽取的样本作为验证集。

### 5. 保留法（Holdout）

**描述**：将数据集划分为训练集和测试集，通常按 70%/30%或 80%/20%的比例划分，不设验证集。

**适用场景**：适用于初步模型训练和快速评估。

**优点**：

- 简单易行。
- 计算开销低。

**缺点**：

- 无法对模型进行验证调整。
- 结果依赖于一次性的划分。

**实际例子**：
对于一个包含 1,000 条样本的数据集，随机划分为 80%训练集（800 条）和 20%测试集（200 条）。

### 6. 分层抽样（Stratified Sampling）

**描述**：按类别比例进行数据划分，确保训练集、验证集和测试集中各类别样本比例一致。

**适用场景**：适用于类别不平衡的数据集。

**优点**：

- 保证各子集中类别分布一致。
- 提高模型评估的公平性。

**缺点**：

- 需要知道类别分布。
- 对于某些类别样本非常少的情况，仍然可能不够稳定。

**实际例子**：
对于一个包含 10,000 条样本的数据集，类别 A 占 30%，类别 B 占 70%，随机划分时确保各类别在训练集、验证集和测试集中的比例分别保持 30%和 70%。

### 7. 时间序列分割（Time Series Split）

**描述**：对于时间序列数据，根据时间顺序进行划分，训练集为过去的数据，验证集和测试集为未来的数据。

**适用场景**：适用于时间序列预测任务。

**优点**：

- 保持时间顺序，符合实际预测场景。
- 避免未来数据泄露。

**缺点**：

- 不能随意打乱数据顺序。
- 对于季节性或周期性数据，需要特别处理。

**实际例子**：
对于一个包含 5 年日数据集，前 4 年数据作为训练集，第 5 年的数据作为验证集和测试集。

### 方法对比表格

| 划分方法        | 优点                                             | 缺点                                           | 适用场景                     |
| --------------- | ------------------------------------------------ | ---------------------------------------------- | ---------------------------- |
| 随机划分法      | 简单易行，计算开销低                             | 结果依赖随机性，数据量少时不适用               | 大多数数据集，数据量较大时   |
| 交叉验证        | 结果稳定，充分利用数据                           | 计算开销较大                                   | 数据量较小，需稳定评估       |
| 留一法交叉验证  | 最大限度利用数据，评估结果可靠                   | 计算开销非常大，对大数据集不实用               | 小数据集，高要求评估         |
| 留 P 法交叉验证 | 平衡计算开销和数据利用率                         | 计算量依然较大                                 | 数据量适中                   |
| 自助法          | 生成多个训练集，评估模型稳定性                   | 某些样本多次抽取，另一些未抽取，计算开销较大   | 不平衡数据集，评估模型稳定性 |
| 保留法          | 简单易行，计算开销低                             | 无法验证调整模型，结果依赖一次性划分           | 初步模型训练和快速评估       |
| 分层抽样        | 保证类别分布一致，提高评估公平性                 | 需要类别分布信息，类别样本少时仍不稳定         | 类别不平衡的数据集           |
| 时间序列分割    | 保持时间顺序，符合实际预测场景，避免未来数据泄露 | 不能打乱数据顺序，需特别处理季节性或周期性数据 | 时间序列预测任务             |

通过上述介绍和对比，可以根据具体的数据集特征和模型需求选择合适的数据划分方法，提高模型训练和评估的效果。
